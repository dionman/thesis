\chapter{Introduction}
\label{chap:chap1}


\nomenclature[A]{\iid}{Independent and identically distributed}
\nomenclature[A]{ELBO}{Evidence Lower Bound}
\nomenclature[A]{DP}{Differentially Private}
\nomenclature[A]{MC}{Monte Carlo}
\nomenclature[A]{CDF}{Cumulative Density Function}
\nomenclature[A]{CDF}{Complementary Cumulative Density Function}

\nomenclature[A]{\reals}{Real numbers}
\nomenclature[A]{\ints}{Integer numbers}
\nomenclature[A]{\nats}{Natural numbers}

\nomenclature[A]{$\plainxent$}{Cross-entropy}
\nomenclature[A]{$\plainkl$}{Kullback-Leibler divergence}
\nomenclature[A]{$\plaindb$}{$\beta$-divergence}

\nomenclature[A]{$\operatorname{diag}$}{Matrix diagonal opertator}
\nomenclature[A]{$\operatorname{tr}$}{Matrix trace operator}
\nomenclature[A]{$\mathbb{P}$}{Probability operator}
\nomenclature[A]{$\mathbb{E}$}{Expectation operator}

\nomenclature[A]{$\operatorname{Var}$}{Variance}
\nomenclature[A]{$\operatorname{Cov}$}{Covariance}
\nomenclature[A]{$\operatorname{Corr}$}{Correlation}
\nomenclature[A]{$\sim$}{Distributed as}

\nomenclature[A]{$\mathcal{N}$}{Normal distribution}
\nomenclature[A]{$\mathcal{T}$}{Student's t-distribution}
\nomenclature[A]{\distNamed{Unif}}{Uniform distribution}
\nomenclature[A]{\distNamed{Gam}}{Gamma distribution}
\nomenclature[A]{\distNamed{Poiss}}{Poission distribution}
\nomenclature[A]{\distNamed{Exp}}{Exponential distribution}
\nomenclature[A]{\distNamed{Beta}}{Beta distribution}
\nomenclature[A]{\distNamed{Dir}}{Dirichlet distribution}
\nomenclature[A]{\distNamed{Bern}}{Bernoulli distribution}
\nomenclature[A]{$\chisq$}{Chi-square distribution}
\nomenclature[A]{$\distUnifSubset$}{Uniform subset distribution}

%\nomenclature[A]{$X$}{Random variable over data space}
\nomenclature[A]{$\Theta$}{Space of model random variables}
\nomenclature[A]{$\mcX^N$ / $(\mcX \times \mcY)^N$}{Data space of $N$ unlabeled/labeled observations}
\nomenclature[A]{$[N]$}{$[1,\ldots,N]$}

\section{Prelude}
\label{sec:prelude}

When faced with a data set too large to be processed all at once, an obvious solution is to retain only part of it. 

\par{Data Summarization and Differential Privacy}

\par{Data Summarization and Outliers Detection}

\section{Thesis Organization}
\label{sec:thesis_organization}
The remainder of the dissertation is organized as follows. \cref{chap:chap2} introduces relevant background and concepts used throughout the thesis. \cref{chap:chap3} sheds light into the anonymity properties of a large-scale longitudinal mobility dataset, revealing a realistic privacy threat that survives in private structured datasets after coarsening individual records. \cref{chap:chap4} presents a general-purpose sparse variational inference algorithm that allows scaling up Bayesian inference in big and high-dimensional datasets via a coreset representation that relies on learnable synthetic datapoints, and introduces a differentially private construction for this coreset:~\psvi~and ~\dpsvi~respectively. \cref{chap:chap5} proposes a sparse variational approximation for robust pseudo-Bayesian posteriors using \bdiv, that can yield reliable summarizations for large-scale datasets in the presence of extensive contamination:~\bcores. Finally, \cref{chap:chap6} concludes the thesis by summarizing our results and discussing future research directions.


This thesis covers material from the following papers:

\begin{quote}
	\fullcite{manousakas2018quantifying}~(\cref{chap:chap3})
	
	\fullcite{psvi}~(\cref{chap:chap4})
	
	\fullcite{beta-cores}~(\cref{chap:chap5})
\end{quote}


In addition, the following paper was written during my PhD but is not discussed in this thesis.

\begin{quote}
	\fullcite{countering}
\end{quote}

