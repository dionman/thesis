\chapter{Introduction}
\label{chap:chap1}

\iffalse
\renewcommand\nomgroup[1]{%
	\item[\bfseries
	\ifstrequal{#1}{A}{Acronyms/Abbreviations}{
		\ifstrequal{#1}{B}{Roman Symbols}{%
			\ifstrequal{#1}{C}{Greek Symbols}{%
				\ifstrequal{#1}{D}{Other Symbols}{
					\ifstrequal{#1}{E}{Superscripts}{
						\ifstrequal{#1}{F}{Subscripts}{
							\ifstrequal{#1}{G}{Distributions}{
								\ifstrequal{#1}{H}{Operators}{
									\ifstrequal{#1}{I}{Mobile Data Abbreviations}{
										\ifstrequal{#1}{J}{Graphs}{
	}}}}}}}}}}]}
\fi

% Abbreviations
\nomenclature[A]{e.g.}{exempli gratia}
\nomenclature[A]{etc.}{et cetera}
\nomenclature[A]{cf.}{confer}
\nomenclature[A]{i.e.}{id est}
\nomenclature[A]{s.t.}{such that}
\nomenclature[A]{iff}{if and only if}
\nomenclature[A]{\iid}{Independent and identically distributed}
\nomenclature[A]{ELBO}{Evidence Lower Bound}
\nomenclature[A]{DP}{Differentially Private}
\nomenclature[A]{KL}{Kullback-Leibler}
\nomenclature[A]{MC}{Monte Carlo}
%\nomenclature[A]{HMC}{Hamiltonian Monte Carlo}
\nomenclature[A]{NUTS}{No-U-Turn Sampler}
\nomenclature[A]{CDF}{Cumulative Density Function}
\nomenclature[A]{CCDF}{Complementary Cumulative Density Function}
\nomenclature[A]{VI}{Variational Inference}
\nomenclature[A]{PSVI}{Pseudocoresets Sparse Variational Inference}
%\nomenclature[A]{\sparsevi}{Sparse VI}
\nomenclature[A]{RANDOM}{Random Sampling Coreset}
\nomenclature[A]{PL}{Privacy Loss}
\nomenclature[A]{RBF}{Radial Basis Function}
\nomenclature[A]{RMSE}{Root-Mean-Square Error}
\nomenclature[A]{PCA}{Principal Components Analysis}
\nomenclature[A]{RHS}{right hand side}
%\nomenclature[A]{MLE}{Maximum Likelihood Estimation}
%\nomenclature[A]{MAP}{Maximum A Posteriori}
\nomenclature[A]{\wrt}{with respect to}

% Roman symbols
\nomenclature[B]{$\mcD$}{Dataset}
\nomenclature[B]{$\mcH$}{Hilbert space}
\nomenclature[B]{$\mcX^N$ / $(\mcX \times \mcY)^N$}{Data space of $N$ unlabeled/labeled observations}
\nomenclature[D]{$[N]$}{$[1,\ldots,N]$}

% Greek symbols
%\nomenclature[C]{$\Theta$}{Space of model random variables}
\nomenclature[C]{$\eps$}{a random variable}
\nomenclature[C]{$\veps$}{a very small non-negative constant}
\nomenclature[C]{$O$}{Upper bound of complexity}
\nomenclature[C]{$\Theta$}{Asymptotically tight upper and lower bound of complexity}
\nomenclature[C]{$\delta(x)$}{Dirac delta function: equals $+\infty$ iff $x=0$, otherwise 0}

% Others
\nomenclature[D]{\reals}{Real numbers}
\nomenclature[D]{\ints}{Integer numbers}
\nomenclature[D]{\nats}{Natural numbers}
\nomenclature[D]{$\#$}{Number of}
\nomenclature[D]{$\mathbb{P}$}{Probability}
\nomenclature[D]{$\plainxent$}{Cross-entropy}
\nomenclature[D]{$\plainkl$}{Kullback-Leibler divergence}
\nomenclature[D]{$\plainCapdb$}{$\beta$-divergence}
\nomenclature[D]{$\plaindb$}{$\beta$-cross-entropy}
\nomenclature[D]{$\sim$}{Distributed as}
\nomenclature[D]{$\propto$}{Proportional to}
\nomenclature[D]{$\defined$}{Defined as}
\nomenclature[D]{$\langle \cdot~,~\cdot \rangle$}{Inner product}
\nomenclature[D]{$\circ$}{Composition of functions}

% Superscripts
\nomenclature[E]{$\widetilde{\phantom{X}}$}{Computed on pseudodata}
\nomenclature[E]{$\widehat{\phantom{X}}$}{Empirical estimate}

% Subscripts

% Distributions
\nomenclature[G]{$\mathcal{N}$}{Normal distribution}
\nomenclature[G]{$\mathcal{T}$}{Student's t-distribution}
\nomenclature[G]{\distNamed{Unif}}{Uniform distribution}
%\nomenclature[G]{\distNamed{Gam}}{Gamma distribution}
%\nomenclature[G]{\distNamed{Poiss}}{Poisson distribution}
%\nomenclature[G]{\distNamed{Exp}}{Exponential distribution}
%\nomenclature[G]{\distNamed{Beta}}{Beta distribution}
%\nomenclature[G]{\distNamed{Dir}}{Dirichlet distribution}
\nomenclature[G]{\distNamed{Bern}}{Bernoulli distribution}
\nomenclature[G]{$\chisq$}{Chi-square distribution}
\nomenclature[G]{$\distUnifSubset$}{Uniform subset distribution}

% Operators
\nomenclature[H]{$\operatorname{diag}$}{Matrix diagonal}
\nomenclature[H]{$\operatorname{tr}$}{Matrix trace}
\nomenclature[H]{$\mathbb{E}$}{Expectation}
\nomenclature[H]{$\operatorname{Var}$}{Variance}
\nomenclature[H]{$\operatorname{Cov}$}{Covariance}
\nomenclature[H]{$\operatorname{Corr}$}{Correlation}

% Mobility data
\nomenclature[I]{MAC}{Media Access Control}
\nomenclature[I]{cid}{Cell tower identifier}
\nomenclature[I]{ID}{Identifier}
\nomenclature[I]{CDR}{Call Data Record}

% Graphs
\nomenclature[J]{$\mcG$, $G$, $V$, $E$}{Space of graphs, Graph, Vertices, Edges}
\nomenclature[J]{SP}{Shortest Path}
\nomenclature[J]{WL}{Weisfeiler-Lehman}
\nomenclature[J]{DK}{Deep graph kernels}

Machine learning pervades most modeling and decision-making tools of modern society: scientists rely on the wealth of stored medical records to decipher the underlying causes of diseases, web-scale recommender systems learn from users experience to suggest music, movies, and products tailored to our habits, and driving-intelligence systems are capable to navigate self-driving cars in complex, never-seen-before environments. 

From the statistical point of view, Bayesian modeling offers a powerful unifying framework where experts and practitioners alike can leverage domain-specific knowledge, learn from new observations, share statistical strength across components of hierarchical models, and take advantage of predictions which can account for model uncertainty. Having access to larger datasets is invaluable for statistical models, as it allows more insights into the process that gives rise to the data. 

At the same time, handling massive-scale datasets in machine learning instigates a number of computational, societal, and statistical reliability challenges. First, beyond basic statistical settings, performing inference---\ie~computing expectations of interest under posterior distributions updated in the light of new observations---does not scale to large datasets; hence, learning in most interesting models requires additional effort from the data analyst to explore the statistical-computational trade-off of the problem, and turn to a suitable approximate inference method instead. Apart from addressing \emph{scalability}, modern approximate inference methods should be also able to offer guarantees of convergence to the exact posterior distribution given sufficient computational resources, admit efficient quality measuring, and work seamlessly in high dimensions, where many of modern large-scale data live (e.g. genes, or social networks).

Secondly, a large fraction of modern massive-scale machine learning applications involves observations stemming from privacy-sensitive data domains, for example health records or behavioural studies. The sensitive information content of such sources makes crucial for data contributors that inference methods satisfy formal guarantees of \emph{statistical privacy}. To this end, the gold standard is relying on the established framework of differential privacy: the existing toolset of privatising mechanisms and tight privacy loss estimation techniques, reinforced by the massive population sizes of modern datasets, allow statistically protecting individual information, yet extracting accurate insights about the population under study.

Thirdly, real-world big data are often highly heterogeneous, contain outliers and noise, or might be subject to data poisoning. The afore-mentioned phenomena are typically expressed as patterns which cannot be fully captured within the parametric assumptions of the statistical model. As a result, standard Bayesian inference techniques, which do not take extra care to downweight the contributions of outlying datapoints, lack \emph{robustness} and, attempting to describe the full set of observations, might eventually yield unreliable posteriors. 

\emph{How should we develop methods for large-scale data analysis that sufficiently address the problem of scalability, while formally preserving privacy and enhancing inferential results with robustness against mismatching observations?} When faced with a dataset too large to be processed all at once, an obvious approach is to retain only a representative part of it. In this thesis, we build on the \emph{data summarization} idea, which is validated by a critical insight in our massive-scale learning setup: when fitting a parametric probabilistic model on a large dataset, much of the data is redundant. Therefore, compressing the dataset under the strategic criterion of maximally reducing redundancy~\wrt a given statistical model, opens an avenue for scalable data analysis without substantially sacrificing the accuracy of methods. The data summarization method of choice in this work is constructing \emph{coresets}: small, weighted collections of points in the data space that can succintly and parsimoniously represent the complete dataset in a problem-dependent way. 

\noindent{\textbf{Data Summarization and Differential Privacy.}}
The aim of summarization is ostensibly in accord with the requirements of privacy, making it a good candidate to build privacy-preserving methods: informally, in both cases the target is to ensure encoding the prevailing patterns of the dataset, without revealing information about any individual datapoint in particular. However, an intricacy lies in that releasing part of the data, though perfectly acceptable for the purposes of coresets, directly breaches privacy, as it obviously exposes the full private information of the summarizing datapoints. Private coresets construction forms a challenging problem of releasing data in the \emph{non-interactive}, or \emph{offline} setting---namely in scenarios where a data owner aims to publicly release randomised privacy-preserving reductions of their data to third-parties, without knowing what statistics might be computed next. Differentially private schemes for coresets applicable in computational geometry already exist in the literature~\citep{feldman09,feldman17}. In the area of machine learning, the idea of releasing private dataset compressions via synthetic datapoints has been pursued in kernel mean embeddings~\citep{balog18} and compressive learning~\citep{schellekens19}, with the utility of the private method scaling adversely with data dimension. Work limited to sparse regression~\citep{zhou08} has considered the high-dimensional data setting and proposed a method that compresses data via random linear or affine transformations. Nevertheless, none of these approaches is directly applicable to summarising for general-purpose Bayesian inference. 

\noindent{\textbf{Data Summarization and Outliers Detection.}} Several approximate inference methods have proved brittle to observations that \emph{"deviate markedly from other members of the sample"}~\citep{grubbs69}. Outliers are a common complication emerging in real-world problems, attributed to limited precision, noise, uncertainty and adversarial behaviour often arising over data collection procedures. Since the pioneering work of~\textcite{tukey60} and~\textcite{definetti61}, discerning outliers has concerned the research community for over 60 years, shaping the area of robust statistics~\citep{huber09}. To this end, non-parametric distance-based techniques are a predominant approach that decouples outliers detection from statistical assumptions regarding the data generating distribution, hence this paradigm has found broad applicability in machine learning and data mining. On the other hand, scaling distance computation to massive datasets is particularly resource intensive, while, further to computational intractability, distance-based analysis in high dimensions faces complications due to the \emph{curse of dimensionality}~\citep{donoho00,vershynin18,wainwright19}. Summarization has been leveraged for the purposes of outlier detection in non-probabilistic clustering in prior work by~\textcite{lucic16outliers}. In the case of Bayesian learning, addressing inference on contaminated data via summarization critically relies on using as criterion of the coreset quality a robustified posterior, that is by definition insensitive to small deviations in the data space. Then the intuition used is that adding an outlier on a summary comprised of a majority of inliers will have an insignificant impact on the quality of the robust posterior defined on the summary points; hence, greedy incremental schemes of summarization can handily reject outlying observations while compressing the dataset.

\section{Thesis statement and main contributions}
\label{sec:thesis-goals}

The focus of this thesis is the development of scalable tools for data analysis on privacy-sensitive and vulnerable to contamination big data. We claim the following statement:

\emph{Automated methods for general-purpose probabilistic inference are typically computationally prohibitive in settings involving massive-scale and high-dimensional data. In contrast, designing principled dataset summarization algorithms enables scaling up learning methods in this data realm, achieving realiable inference results, and addressing concerns of privacy and robustness. Notably, the latter can be achieved without having a substantial bearing on the automation and complexity of the summarization methods.}

Relying on coreset-based dataset summarizations as our fundamental framework for scalability, we adopt a two-pronged approach to tackle each of the aforementioned challenges, and design efficient algorithms that outperform state-of-the-art solutions for the posed problems. 


In particular, the goals of this dissertation are to:

\begin{enumerate}
	\item Identify threats in commonly adopted practices for releasing privacy-sensitive datasets via anonymized coarsened representations of the data.
	\item Propose novel principled methods that can directly address real-word considerations of privacy and robustness when performing inference via summarization, without increasing the corresponding computational and memory footprint compared to the existing state-of-the-art methods.
\end{enumerate}

The central contributions of the thesis are the following:

\begin{itemize}
	\item We analyse the anonymity of individual data in a large-scale behavioural study, and develop a \emph{reidentification attack that exploits structural patterns similarity} to link users' records in the absence of identifiers in their state space.
	\item We introduce a novel variational formulation for Bayesian coresets construction that utilises approximations within a \emph{family of efficient variational distributions} with learnable weights and locations of \emph{pseudodata} as variational parameters.
	 Leveraging the use of learnable pseudodata, we show that our variational formulation enables substantially more rapid improvement in summarization quality for high-dimensional data in the small coresets regime, compared to existing coreset schemes that are constrained to use points from the original dataset. 
	%\item We show that the use of learnable pseudodata enables substantially more efficient summarization quanlity for high-dimensional data, compared to existing coreset constructions that are constrained to use points from the original dataset. For the latter, we prove a data dimensionality dependent bound in optimal approximation quality 
	%\item We theoretically show data dimension dependent limitations in optimal approximation quality for small summary sizes, achievable by existing coreset constructions that are constrained to use points from the original dataset; subsequently, we show that the use of learnable pseudodata enables overcoming the data-dimension constraints, and offers rapid improvement in approximation quality for small coreset sizes.
	 We provide an efficient black-box batch optimization scheme that can attain a good approximate posterior within the above mentioned variational family, and use standard randomization tools to yield differentially private versions of this variational posterior for privacy-preserving data analysis.
	\item We review Bayesian coresets behaviour in corrupted datasets and show deficiencies of standard constructions when dealing with outliers and poisoning.
	 Using tools from robust divergences, we propose approximate inference within a \emph{robustified family of sparse variational approximations} for reliable summarization in the presence of data contamination.
	 We develop a black-box incremental optimization scheme for constructing an approximation within this variational family, and evaluate its applicability in scenarios of summarization both over datapoints and over data minibatches.
\end{itemize}

A recurring theme in our approach is to exploit inherent data redundancy, in order to simultaneously achieve efficient data analysis and satisfy the objectives of privacy and robustness. Importantly, the computation of redundancy is adapted to the statistical model used to describe the data via the likelihood function, offering increased efficiency for the purposes of learning---as our methods, guided by the data likelihood function, manage to preserve reliable \emph{approximate sufficient statistics} of the full data collection, despite retaining only a tiny fraction of it. Directly randomizing the sufficient statistics computation via a differentially private mechanism addresses formally the protection of privacy, and allows us to avoid adding more noise than necessary, as we only have to hide the part of individual datapoints' information which is passed to the sufficient statistics instead of their full information. On the robustness front, our framework identifies datapoints that deviate from our statistical assumptions and downweights their contribution over inference on the dataset, distilling them in this way from the extracted summary. Overall, our methods indicate that privacy and robustness on both counts are in accordance to the fundamental problem that data summarization aims to resolve: encapsulating aggregate information for a statistical model of interest, while limiting the impact of each individual datapoint's particulars.


\section{Organization of the dissertation}
\label{sec:thesis-organization}
The remainder of the dissertation is organized as follows. 

\cref{chap:chap2} introduces relevant background and concepts used throughout the thesis. 

\cref{chap:chap3} sheds light into the anonymity properties of a large-scale longitudinal mobility dataset, revealing a realistic privacy threat that survives in a release of sensitive structured data, despite anonymizing and coarsening individual behavioural records. 

\cref{chap:chap4} presents a general-purpose variational inference algorithm that allows scaling up Bayesian inference in big and high-dimensional datasets via a coreset representation that relies on learnable synthetic datapoints~(\psvi). Additionally, it develops a differentially private construction for this coreset~(\dpsvi). 

\cref{chap:chap5} proposes a sparse variational approximation for robust generalized Bayesian posteriors using \bdiv, that can yield reliable summarizations for large-scale datasets in the presence of extensive contamination~(\bcores). 

Finally, \cref{chap:chap6} concludes the thesis by summarizing our results and discussing future research directions.


This thesis covers material from the following publications:

\begin{quote}
	\fullcite{manousakas2018quantifying}~(\cref{chap:chap3})
	
	\fullcite{psvi}~(\cref{chap:chap4})
	
	\fullcite{beta-cores}~(\cref{chap:chap5})
\end{quote}


In addition, the following paper was written during my PhD but is not discussed in this thesis:

\begin{quote}
	\fullcite{countering}
\end{quote}

