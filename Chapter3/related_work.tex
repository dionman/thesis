\section{Related work}


\subsection{Mobility deanonymization}

Protecting the anonymity of personal mobility is notoriously difficult due to sparsity~\citep{aggarwal2008}, and hence mobility data are often vulnerable to deanonymization attacks~\citep{Narayanan2008}.
Numerous studies into location privacy have shown that, even when an individual's data are anonymized, they continue to possess unique patterns that can be exploited by a malicious adversary with access to auxiliary information.
\textcite{Zang2011} analysed nationwide call-data records (\emph{CDR}s) and showed that releasing the $N$ most frequently visited places, so called \emph{top$-N$} data, correlated with publicly released side information, resulted in privacy risks, even for small values of $N$s.
This finding underlines the need for reductions in spatial or temporal data fidelity before publication.
Further, \textcite{DeMontjoye2013} quantified the unicity of human mobility on a mobile phone dataset of approximately $1.5M$ users with intrinsic temporal resolution of one hour and a 15-month measurement period.
They found that four random spatio-temporal points suffice to uniquely identify $ 95\% $ of the traces.
They also observe that the uniqueness of traces decreases as a power law of spatio-temporal granularity, stressing the hardness of achieving privacy via obfuscation of time and space information.

Several inference attacks on longitudinal mobility are based on probabilistic models trained on individual traces, and rely on the regularity of human mobility.
\textcite{deMulder08} developed a reidentification technique by building a Markov model for each individual in the training set, and then using this to reidentify individuals in the test set by likelihood maximisation.
Similarly,~\textcite{Gambs2014} used Markov chains to model mobility traces in support of reidentification.

\textcite{Naini2016a} explored the privacy impact of releasing statistics of individuals' mobility traces in the form of histograms, instead of their actual location information. They demonstrated that even this statistical information suffices to successfully recover the identity of individuals in datasets of few hundred people, via matching labeled and unlabeled histograms of a population.
Other researchers have investigated the privacy threats stemming from information sharing on location-based social networks, including the impact of location semantics on the difficulty of reidentification~\citep{privacyAndTheCity} and location inference~\citep{Agir}.

All the above-mentioned previous work assumes that locations are expressed using a universal symbol or global identifier, either corresponding to (potentially obfuscated) geographic coordinates, or pseudonymous stay points.
Hence, cross-referencing between individuals in the population is possible.
This is inapplicable when location information is anonymized separately for each individual.
\textcite{LinMobile} presented a user verification method in this setting.
It is based on statistical profiles of individual indoor and outdoor mobility, including cell tower ID and WiFi access point information.
In contrast, here we employ network representations based solely on cell tower ID sequences without explicit time information.

Often, studies in human mobility aim to model properties of a population, thus location data are published as aggregate statistics computed over the locations of individuals.
This has traditionally been considered a secure way to obfuscate the sensitive information contained in individual location data, especially when released aggregates conform to $ k-$anonymity principles~\citep{sweeney2002k}.
However, recent results have questioned this assumption.
\textcite{xu2017trajectory} recovered movement trajectories of individuals with accuracy levels of between $73\%$ and $91\%$ from aggregate location information computed from cellular location information involving $100,000$ users. Similarly, ~\textcite{pyrgelis2017does} performed a set of inference attacks on aggregate location time-series data and detected serious privacy loss, even when individual data are perturbed by differential privacy mechanisms before aggregation.

\subsection{Anonymity of graph data }
Most of the aforementioned data can be represented as \emph{microdata} with rows of fixed dimensionality in a table.
Microdata can thus be embedded into a vector space.
In other applications, datapoints are \emph{relational} and can be naturally represented as \emph{graphs}.
Measuring the similarity of such data is significantly more challenging, since there is no definitive method.
Deanonymization attacks on graphs have mostly been studied in the context of social networks and aimed to either align nodes between an auxiliary and an unknown targeted graph~\citep{narayanan2009anonymizing, sharad2014}, or quantify the leakage of private information of a graph node via its neighbors~\citep{zheleva09}.

In the problem studied here, \emph{each individual's information is an entire graph}, rather than a node in a graph or a node attribute, and thus deanonymization is reduced to a \emph{graph matching or classification} problem.
To the best of our knowledge, this is the first attempt to deanonymize an individual's structured data by applying graph similarity metrics.
Since we are looking at relational data, not microdata, standard theoretical results on microdata anonymization, such as differential privacy~\citep{dwork2006calibrating}, are not directly applicable.
However, metrics related to structural similiarity, including $k-$anonymity, can be seamlessly generalized in this framework.

\subsection{Approximate graph matching}
The problem of matching graphs according to their structural similarity has emerged in research under different contexts and formulations. To clearly position our formulation in the related literature, we first draw a distinction between two primary instantiations of the problem: (\emph{i}) \emph{Network alignment} corresponds to the problem of matching pairs of nodes across graphs that correspond to distorted versions of the the same underlying graph. (\emph{ii}) \emph{Graph matching} is the problem of uncovering matching members across two datasets of graphs that are assumed to form two distorted subsets of the same population of underlying graphs. The data linkability question considered in the context of our work is an instance of the latter problem.

Exact network alignment corresponds to the problem of graph isomorphism, which admits no known polynomial algorithm (although is broadly conjectured not to belong to the family of NP-Hard problems~\citep{schoening88}). Approximate network alignment admits different solutions, depending on the given information about the graph (e.g. whether the graph nodes are labeled, or whether alignment for a subset of nodes is known).~\textcite{kazemi15} proposed a percolation-based algorithm that, leveraging a partially correct seed of node matches, can rapidly expand it to larger matching sets.~\textcite{pedarsani13} used a seedless Bayesian approach assuming a distortion model which describes how observations were obtained from the original graph. Via introducing additional heuristic functions on the results of alignment, network alignment methods can produce distances applicable to approximate graph matching---for instance,~\textcite{mishinev20} proposed a normalized edge overlap metric that allowed transforming the previous two methods into a network distance function.

Graph matching can be approached via computations of a problem dependent similarity metric applicable on arbitrary graphs, that attributes small values to similarly looking graphs and large values to graphs that look dissimilar. For the purposes of supervised learning or data linking, this metric can be relaxed to not strictly satisfy the mathematical definition of a distance metric, e.g. not obey the triangle inequality, as long as it reasonably captures a quantification of structural similarity. In a recent work,~\textcite{chowdhury19} defined a graph distance using an approximation of the optimal transportation function between graphs.
