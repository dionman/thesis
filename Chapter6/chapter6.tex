\chapter{Conclusions}
\label{chap:chap6}
\renewcommand*{\MyPath}{../Chapter6}%
\newcommand{\etal}{\textit{et al}.}
\newcommand{\ie}{\textit{i}.\textit{e}.}

In this thesis, we have presented three original pieces of work drawing on the importance of dataset reductions for learning in the massive data scale: Our premise has been that principled dataset summarization methods can be harsenessed to enable scalable approximations for the purposes of inference on large data without compromising privacy and robustness of learning.
In this section, we briefly summarize our key contributions and suggest directions for future research.

\section{Summary}
\label{sec:summary}

\subsection{Privacy Loss of Coarsified Structured Data}
\label{subsec:ch3-summary}


\subsection{Privacy-Preserving Bayesian Coresets in High-dimensions}
\label{subsec:ch4-summary}

\subsection{Robust Bayesian Coresets on Contaminated Datasets}
\label{subsec:ch4-summary}


\section{Future Research Directions}
\label{sec:future-research-directions}
The summarization frameworks presented in this thesis allow numerous probabilistic models to be tractably and reliably deployed in practice. Yet they allude to a realm of so far unexplored research questions, some of which we overiew in the remainder of this section, thus concluding the thesis.

\subsection{Coresets for Models with Structured Likelihoods}
\label{subsec:structure-liks}

Our variational formulations for coreset construction~\cref{eq:pseudo-coreset-vi,eq:coreset-vi} use the assumption that the data likelihood function gets factorised as a product of individual datapoint potentials. To the best of our knowledge the idea of constructing coresets has yet been pursued in models with structured likelihood functions, including time-series and point processes. Recent results on parameter estimation for Hawkes processes using uniform downsampling~\citep{li19} indicate important improvements in efficiency when learning in massive temporal event sequences, even without optimizing for redundancy in the extracted dataset samples.

\subsection{Implicit Differential Privacy Amplification of Data-dependent Summarizations}
\label{subsec:implicit-dp-amplification}

In~\cref{chap:chap4} we presented an optimization scheme that yields Bayesian coreset constructions under explicit differential privacy quarantees. A known result in DP literature is that incorporating random sampling in data analysis has implicit privacy amplification effects, \ie~that an algorithm has higher privacy guarantees when run on a random subset of the datapoints instead of the full dataset~\citep{li12, beimel13, bassily14, abadi16}. More recently, Balle \etal~\citep{balle18} presented a unifying methodology that utilises couplings and divergences to reason about DP amplification effects of several random sampling methods~(including Poisson subsampling and sampling with/without replacement), under different data neighbouring relations. Existing research makes a common assumption that simplifies privacy analysis, but is violated in the case of coresets: the sampling distribution is data-independent. It remains an open-question whether similar approaches can be used to argue about implicit DP amplification when replacing a privacy-sensitive dataset with a coreset---in primitive schemes, coreset construction simply takes the form of importance sampling~\citep{bachem17}. Investigating DP amplification under data-dependent sampling is a direction with far-reaching implications that can lead to tighter privacy analysis not only in the case of coresets, but more broadly in all machine learning applications involving importance sampling, which is already a corenestone of many state-of-the-art stochastic learning methods. 


\subsection{Human-oriented Summaries for Scalable Inference}
\label{subsec:human-oriented-pseudodata}

In~\cref{chap:chap4} we presented a method utilising learnable batches of pseudodata to summarize a much larger dataset. Naturally this coreset construction bears the potential of reducing the interpretability of learned pseudodata, since summarizing datapoints are now not a subset of the original dataset but rather the result of a task-specific optimization routine. To remedy potential interpretability issues, further interpretability constraints can be explicitly incorporated in the optimization formulation of pseudocoreset variational inference of~\cref{eq:pseudo-coreset-vi}.

Beyond the quest of interpretability, further research is required on examining other desiderata in human-oriented inference. To name a few, deletion-robustness is often sought or imposed on methods for large-scale data analysis~\citep{mirzasoleiman17, ginart19}: user's \emph{right-to-be-forgotten} is related to imposing bounds on the effects of removing an individual datapoint from an existing dataset and can be approximately satisfied under differential privacy. Moreover, group \emph{fairness} is one more topic that necessitates further investigation: without special treatment, reducing datasets will potentially transfer existing inequalities between groups in the summary, hence a different construction may be sought when aiming to ameliorate unfairness in scalable inference.  